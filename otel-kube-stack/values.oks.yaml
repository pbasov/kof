#USER-SUPPLIED VALUES:
cleanupJob:
  enabled: true
  existingServiceAccount: ""
  image:
    digest: ""
    repository: bitnami/kubectl
    tag: latest
clusterName: ""
clusterRole:
  annotations: {}
  enabled: true
  rules: []
collectors:
  cluster:
    config:
      exporters:
        debug: {}
      processors:
        batch:
          send_batch_max_size: 1500
          send_batch_size: 1000
          timeout: 1s
        transform/k8scluster:
          metric_statements:
            - context: scope
              conditions:
                - IsMatch(scope.name, "k8scluster")
              statements:
                - set(resource.attributes["service.name"], "k8scluster")
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.pod.uid"])
            - context: resource
              conditions:
                - resource.attributes["service.instance.id"] == nil
              statements:
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.node.uid"])
            - context: datapoint
              statements:
                - set(datapoint.cache["attrs"], resource.attributes)
                - keep_matching_keys(datapoint.cache["attrs"], "k8s.*")
                - merge_maps(datapoint.attributes, datapoint.cache["attrs"], "insert")
        resourcedetection:
          detectors:
          - env
          - kubeadm
          override: false
          timeout: 2s
      receivers: {}
      service:
        pipelines:
          logs:
            processors:
            - resourcedetection
            - batch
            receivers:
            - k8sobjects
          metrics:
            processors:
            - resourcedetection
            - batch
            - transform/k8scluster
            receivers:
            - k8s_cluster
    enabled: true
    mode: deployment
    presets:
      clusterMetrics:
        enabled: true
      kubernetesAttributes:
        enabled: true
      kubernetesEvents:
        enabled: true
    replicas: 1
    resources:
      limits:
        cpu: 200m
        memory: 500Mi
      requests:
        cpu: 100m
        memory: 250Mi
    suffix: cluster-stats
  target-allocator:
    targetAllocator:
      allocationStrategy: per-node
      allocationFallbackStrategy: consistent-hashing
      enabled: true
      image: ghcr.io/open-telemetry/opentelemetry-operator/target-allocator:main
      prometheusCR:
        enabled: true
        podMonitorSelector: {}
#        scrapeInterval: 30s
        serviceMonitorSelector: {}
    config:
      processors:
        batch:
          send_batch_max_size: 1500
          send_batch_size: 1000
          timeout: 1s
        resourcedetection:
          detectors:
          - env
          - system
  #        - ec2
  #        - gcp
  #        - azure
  #        - k8snode
  #        - kubeadm
          override: false
          timeout: 2s
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
      service:
        pipelines:
          logs:
            receivers:
              - otlp
            exporters:
              - debug
#          traces:
#            receivers:
#              - otlp
#            exporters:
#              - debug
          metrics:
            receivers:
              - prometheus
            processors:
              - resourcedetection
              - batch
    enabled: true
    mode: daemonset
    presets:
      kubernetesAttributes:
        enabled: true
    resources:
      limits:
        cpu: 200m
        memory: 500Mi
      requests:
        cpu: 100m
        memory: 250Mi
#    scrape_configs_file: ""
    suffix: ta-daemon
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
  daemon:
    env:
      - name: PATH
        value: "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/hostfs/usr/bin"
      - name: LD_LIBRARY_PATH
        value: "/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/hostfs/lib/x86_64-linux-gnu:/hostfs/usr/lib/x86_64-linux-gnu:/hostfs/usr/lib/x86_64-linux-gnu/systemd"
    config:
      extensions:
        file_storage:
          directory: /var/lib/otelcol
      processors:
        batch:
          send_batch_max_size: 1500
          send_batch_size: 1000
          timeout: 1s
        transform/syslog:
          error_mode: ignore
          log_statements:
            - context: log
              conditions:
                - attributes["log.file.path"] == "/hostfs/var/log/syslog"
              statements: 
                - merge_maps(log.cache, ExtractGrokPatterns(log.body, "%{SYSLOGLINE}", false), "upsert")
                - merge_maps(log.cache, ExtractGrokPatterns(log.body, "%{(TIMESTAMP_ISO8601|SYSLOGTIMESTAMP):timestamp} %{SYSLOGHOST:host.name} (%{SYSLOGPROG}:)?\\s*%{GREEDYDATA:message}", false, ["GREEDYMULTILINE=(.|\\n)*"]), "upsert") 
                - merge_maps(log.cache, ExtractGrokPatterns(log.cache["SYSLOGPROG"], "%{DATA:process.executable.name}(?:\\[%{POSINT:process.pid})\\]", true), "upsert") where log.cache["SYSLOGPROG"] != nil
                - set(log.body, log.cache["message"])
                - set(log.attributes["syslog.timestamp"], log.cache["timestamp"])
                - set(log.attributes["syslog.facility"], log.cache["SYSLOGFACILITY"])
                - >
                  keep_keys(
                    log.cache, 
                    ["host.name", 
                    "process.pid", 
                    "process.executable.name" 
                    ])
                - merge_maps(log.attributes, log.cache, "upsert") 
        transform/kubeletstats:
          metric_statements:
            - context: scope
              conditions:
                - IsMatch(scope.name, "kubeletstats")
              statements:
                - set(resource.attributes["service.name"], "kubeletstats")
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.pod.uid"])
        transform/hostmetrics:
          metric_statements:
            - context: scope
              conditions:
                - IsMatch(scope.name, "hostmetrics")
              statements:
                - set(resource.attributes["service.name"], "hostmetrics")
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.node.uid"])
        transform/k8snode:
          metric_statements:
            - context: datapoint
              statements:
                - set(datapoint.attributes["node"], resource.attributes["k8s.node.name"])
                - set(datapoint.attributes["nodename"], resource.attributes["k8s.node.name"])
        resourcedetection:
          detectors:
          - env
          - system
          - ec2
          - gcp
          - azure
          - k8snode
          - kubeadm
          override: false
          timeout: 2s
      receivers:
        filelog/containers:
#          storage: file_storage
          exclude: []
          include:
          - /var/log/pods/*/*/*.log
          include_file_name: false
          include_file_path: true
          operators:
          - id: container-parser
            max_log_size: 102400
            type: container
          - id: extract_metadata_from_filepath
            on_error: drop_quiet
            parse_from: attributes["log.file.path"]
            regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
            type: regex_parser
          - from: attributes.container_name
            to: resource["k8s.container.name"]
            type: move
          - from: attributes.namespace
            to: resource["k8s.namespace.name"]
            type: move
          - from: attributes.pod_name
            to: resource["k8s.pod.name"]
            type: move
          - from: attributes.restart_count
            to: resource["k8s.container.restart_count"]
            type: move
          - from: attributes.uid
            to: resource["k8s.pod.uid"]
            type: move
          - id: extract_log_level
            on_error: send_quiet
            parse_from: body
            regex: (?i)(?P<log_level>(panic|fatal|crit|alert|emerg|err(?:or)?|warn(?:ing)?|info|debug|notice|trace|[EFDWI]\d{4}))
            type: regex_parser
          - id: extract_short_letter
            if: ("log_level" in attributes)
            on_error: send_quiet
            parse_from: attributes["log_level"]
            regex: (?i)(?P<log_level>[EFDWI])\d{4}
            type: regex_parser
          - field: attributes.log_level
            if: '!("log_level" in attributes)'
            type: add
            value: info
          - mapping:
              debug:
              - debug
              - d
              error:
              - error
              - err
              - failed
              - e
              fatal:
              - fatal
              - crit
              - alert
              - emerg
              - panic
              - f
              info:
              - info
              - notice
              - trace
              - i
              warn:
              - warn
              - warning
              - w
            overwrite_text: true
            parse_from: attributes.log_level
            preset: none
            type: severity_parser
          - cache:
              size: 128
            field: attributes.log_level
            type: remove
          retry_on_failure:
            enabled: true
          start_at: end

        filelog/syslog:
#          storage: file_storage
          exclude: []
          include:
          - /hostfs/var/log/syslog
          include_file_name: false
          include_file_path: true
#          operators:
#            - type: syslog_parser
#              protocol: rfc3164
#              allow_skip_pri_header: true
          retry_on_failure:
            enabled: true
          start_at: end


#        journald:
#          directory: /hostfs/var/log/journal
#          operators:
#            - type: journald_input
#              id: journald_input
#              directory: /hostfs/var/log/journal
#              matches: []
#              all: true
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
      service:
        extensions:
          - basicauth/metrics
          - basicauth/logs
#          - file_storage
        pipelines:
          logs:
            processors:
            - resourcedetection
            - transform/syslog 
            - batch
            receivers:
            - otlp
            - filelog/containers
            - filelog/syslog
#            - journald
          metrics:
            processors:
            - resourcedetection
            - transform/kubeletstats
            - transform/hostmetrics
            - transform/k8snode
            - batch
            receivers:
            - otlp
          traces:
            exporters:
            - debug
            processors:
            - resourcedetection
            - batch
            receivers:
            - otlp
    enabled: true
    mode: daemonset
    presets:
      hostMetrics:
        enabled: true
      kubeletMetrics:
        enabled: true
      kubernetesAttributes:
        enabled: true
#      logsCollection:
#        enabled: true
    resources:
      limits:
        cpu: 200m
        memory: 500Mi
      requests:
        cpu: 100m
        memory: 250Mi
    scrape_configs_file: daemon_scrape_configs.yaml
    podSecurityContext:
      supplementalGroups: [4, 999]
#    securityContext:
#      supplementalGroups: [4000]
    suffix: daemon
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    volumes:
      - name: linker
        hostPath:
          path: /lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
      - name: varlogpods
        hostPath:
          path: /var/log/pods
      - name: varlibotelcol
        hostPath:
          path: /var/lib/otelcol
          type: DirectoryOrCreate
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
    volumeMounts:
      - name: linker
        mountPath: /lib64/ld-linux-x86-64.so.2
        readOnly: true
      - name: varlogpods
        mountPath: /var/log/pods
        readOnly: true
      - name: varlibdockercontainers
        mountPath: /var/lib/docker/containers
        readOnly: true
      - name: varlibotelcol
        mountPath: /var/lib/otelcol
  controller-k0s:
    config:
      processors:
        batch:
          send_batch_max_size: 1500
          send_batch_size: 1000
          timeout: 1s
        transform/kubeletstats:
          metric_statements:
            - context: scope
              conditions:
                - IsMatch(scope.name, "kubeletstats")
              statements:
                - set(resource.attributes["service.name"], "kubeletstats")
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.pod.uid"])
        transform/hostmetrics:
          metric_statements:
            - context: scope
              conditions:
                - IsMatch(scope.name, "hostmetrics")
              statements:
                - set(resource.attributes["service.name"], "hostmetrics")
                - set(resource.attributes["service.instance.id"], resource.attributes["k8s.node.uid"])
        transform/k8snode:
          metric_statements:
            - context: datapoint
              statements:
                - set(datapoint.attributes["node"], resource.attributes["k8s.node.name"])
                - set(datapoint.attributes["nodename"], resource.attributes["k8s.node.name"])
        resourcedetection:
          detectors:
          - env
          - system
          - ec2
          - gcp
          - azure
#          - k8snode
#          - kubeadm
          override: false
          timeout: 2s
      receivers:
        kubeletstats:
          auth_type: serviceAccount
          collection_interval: 10s
          endpoint: https://${env:OTEL_K8S_NODE_IP}:10250
          extra_metadata_labels:
          - container.id
          - k8s.volume.type
          k8s_api_config:
            auth_type: serviceAccount
          metric_groups:
          - node
          - pod
          - volume
          - container
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
      service:
        pipelines:
          logs:
            processors:
            - resourcedetection
            - batch
            receivers:
            - otlp
          metrics:
            processors:
            - resourcedetection
            - transform/kubeletstats
            - transform/hostmetrics
            - transform/k8snode
            - batch
            receivers:
            - otlp
            - prometheus
          traces:
            processors:
            - resourcedetection
            - batch
            receivers:
            - otlp
    enabled: true
    mode: daemonset
    hostNetwork: true
    presets:
      hostMetrics:
        enabled: false
      kubeletMetrics:
        enabled: false
      kubernetesAttributes:
        enabled: false
      logsCollection:
        enabled: false
    resources:
      limits:
        cpu: 200m
        memory: 500Mi
      requests:
        cpu: 100m
        memory: 250Mi
    scrape_configs_file: k0s_scrape_configs.yaml
    nodeSelector: 
      node-role.kubernetes.io/control-plane: "true"
    suffix: controller-k0s-daemon
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    volumes:
      - name: hostfs
        hostPath:
          path: /
    volumeMounts:
      - name: hostfs
        mountPath: /hostfs
        readOnly: true
        mountPropagation: HostToContainer
coreDns:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: 9153
    targetPort: 9153
  serviceMonitor:
    additionalLabels: {}
    enabled: true
    interval: ""
    jobLabel: jobLabel
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    port: http-metrics
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector: {}
    targetLimit: 0
crds:
  install: false
defaultCRConfig:
  additionalContainers: []
  affinity: {}
  annotations: {}
  args: {}
  autoscaler: {}
  clusterRoleBinding:
    clusterRoleName: ""
    enabled: true
  config:
    exporters:
      debug:
        verbosity: detailed
      otlphttp/logs:
        auth:
          authenticator: basicauth/logs
        logs_endpoint: https://vmauth.g.vkuklin-k0f-4.cso-k0rdent-lab-team.eu-cloud.mirantis.net/vls/insert/opentelemetry/v1/logs
        tls:
          insecure_skip_verify: true
      otlphttp/traces:
        endpoint: https://jaeger.g.vkuklin-k0f-4.cso-k0rdent-lab-team.eu-cloud.mirantis.net/collector
        tls:
          insecure_skip_verify: true
      prometheusremotewrite:
#        resource_to_telemetry_conversion:
#          enabled: true
        external_labels:
          clusterName: vkuklin-k0f-4-eu-openstack-cluster-deployment
        auth:
          authenticator: basicauth/metrics
        endpoint: https://vmauth.g.vkuklin-k0f-4.cso-k0rdent-lab-team.eu-cloud.mirantis.net/vm/insert/0/prometheus/api/v1/write
        tls:
          insecure_skip_verify: true
    processors:
    extensions:
      basicauth/logs:
        client_auth:
          password: ppassword
          username: uusername
      basicauth/metrics:
        client_auth:
          password: ppassword
          username: uusername
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs: 
          - job_name: dummy
            scrape_interval: 600s
            static_configs:
              - targets: []
        api_server:
          enabled: true
          server_config:
            endpoint: localhost:9090
    service:
      extensions:
      - basicauth/metrics
      - basicauth/logs
      pipelines:
        logs:
          exporters:
          - otlphttp/logs
          - debug
        metrics:
          exporters:
          - prometheusremotewrite
          - debug
        traces:
          exporters:
          - otlphttp/traces
          - debug
          receivers:
          - otlp
  configmaps: []
  enabled: false
  env: []
  fullnameOverride: ""
  hostNetwork: false
  image:
    digest: ""
    pullPolicy: IfNotPresent
    repository: otel/opentelemetry-collector-k8s
    tag: ""
  initContainers: []
  labels: {}
  lifecycle: {}
  livenessProbe: {}
  managementState: managed
  mode: deployment
  nodeSelector: {}
  observability: {}
  podAnnotations: {}
  podDisruptionBudget: {}
  podSecurityContext: {}
  ports: []
  presets:
    clusterMetrics:
      enabled: false
    hostMetrics:
      enabled: false
    kubeletMetrics:
      enabled: false
    kubernetesAttributes:
      enabled: false
      extractAllPodAnnotations: false
      extractAllPodLabels: false
    kubernetesEvents:
      enabled: false
    logsCollection:
      enabled: false
      includeCollectorLogs: true
      maxRecombineLogSize: 102400
      storeCheckpoints: false
  priorityClassName: ""
  resources:
    limits:
      cpu: 250m
      memory: 128Mi
    requests:
      cpu: 250m
      memory: 64Mi
  scrape_configs_file: ""
  securityContext: {}
  serviceAccount: ""
  shareProcessNamespace: false
  suffix: collector
  targetAllocator: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: []
  updateStrategy: {}
  upgradeStrategy: automatic
  volumeClaimTemplates: []
  volumeMounts: []
  volumes: []
extraEnvs: []
fullnameOverride: ""
instrumentation:
  annotations: {}
  apacheHttpd: {}
  dotnet: {}
  enabled: false
  env: []
  exporter:
    endpoint: http://collector-collector:4317
  go: {}
  java: {}
  labels: {}
  nginx: {}
  nodejs: {}
  propagators:
  - tracecontext
  - baggage
  - b3
  - b3multi
  - jaeger
  - xray
  - ottrace
  python: {}
  resource:
    addK8sUIDAttributes: true
    resourceAttributes: {}
  sampler: {}
kube-state-metrics:
  namespaceOverride: ""
  prometheus:
    monitor:
      enabled: true
      honorLabels: true
      interval: ""
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      metricRelabelings: []
      proxyUrl: ""
      relabelings: []
      sampleLimit: 0
      scrapeTimeout: ""
      targetLimit: 0
  rbac:
    create: true
  releaseLabel: true
  selfMonitor:
    enabled: false
kubeApiServer:
  enabled: true
  serviceMonitor:
    additionalLabels: {}
    interval: ""
    jobLabel: component
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings:
    - action: drop
      regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
      sourceLabels:
      - __name__
      - le
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector:
      matchLabels:
        component: apiserver
        provider: kubernetes
    targetLimit: 0
  tlsConfig:
    insecureSkipVerify: false
    serverName: kubernetes
kubeControllerManager:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: null
    targetPort: null
  serviceMonitor:
    additionalLabels: {}
    enabled: true
    https: null
    insecureSkipVerify: null
    interval: ""
    jobLabel: jobLabel
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    port: http-metrics
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector: {}
    serverName: null
    targetLimit: 0
kubeDns:
  enabled: false
  service:
    dnsmasq:
      port: 10054
      targetPort: 10054
    skydns:
      port: 10055
      targetPort: 10055
  serviceMonitor:
    additionalLabels: {}
    dnsmasqMetricRelabelings: []
    dnsmasqRelabelings: []
    interval: ""
    jobLabel: jobLabel
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector: {}
    targetLimit: 0
kubeEtcd:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: 2381
    targetPort: 2381
  serviceMonitor:
    additionalLabels: {}
    caFile: ""
    certFile: ""
    enabled: true
    insecureSkipVerify: false
    interval: ""
    jobLabel: jobLabel
    keyFile: ""
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    port: http-metrics
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    scheme: http
    selector: {}
    serverName: ""
    targetLimit: 0
kubeProxy:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: 10249
    targetPort: 10249
  serviceMonitor:
    additionalLabels: {}
    enabled: true
    https: false
    interval: ""
    jobLabel: jobLabel
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    port: http-metrics
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector: {}
    targetLimit: 0
kubeScheduler:
  enabled: true
  endpoints: []
  service:
    enabled: true
    port: null
    targetPort: null
  serviceMonitor:
    additionalLabels: {}
    enabled: true
    https: null
    insecureSkipVerify: null
    interval: ""
    jobLabel: jobLabel
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    metricRelabelings: []
    port: http-metrics
    proxyUrl: ""
    relabelings: []
    sampleLimit: 0
    selector: {}
    serverName: null
    targetLimit: 0
kubeStateMetrics:
  enabled: true
kubelet:
  enabled: true
  namespace: kube-system
  serviceMonitor:
    cAdvisor: true
    honorLabels: true
    honorTimestamps: true
    https: true
    interval: ""
    probes: true
kubernetesServiceMonitors:
  enabled: true
  ignoreNamespaceSelectors: false
namespaceOverride: ""
nodeExporter:
  enabled: true
opAMPBridge:
  addManagedLabel: false
  addReportingLabel: true
  affinity: {}
  capabilities:
    AcceptsOpAMPConnectionSettings: true
    AcceptsOtherConnectionSettings: true
    AcceptsRemoteConfig: true
    AcceptsRestartCommand: true
    ReportsEffectiveConfig: true
    ReportsHealth: true
    ReportsOwnLogs: true
    ReportsOwnMetrics: true
    ReportsOwnTraces: true
    ReportsRemoteConfig: true
    ReportsStatus: true
  clusterRole:
    annotations: {}
    enabled: true
    rules: []
  componentsAllowed: {}
  enabled: false
  endpoint: http://opamp-server:8080
  env: []
  envFrom: []
  headers: {}
  hostNetwork: false
  image:
    digest: ""
    pullPolicy: IfNotPresent
    repository: ghcr.io/open-telemetry/opentelemetry-operator/operator-opamp-bridge
    tag: ""
  podAnnotations: {}
  podSecurityContext:
    fsGroup: 1000
  ports: []
  priorityClassName: ""
  resources:
    limits:
      cpu: 250m
      memory: 256Mi
    requests:
      cpu: 250m
      memory: 256Mi
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
  serviceAccount: ""
  tolerations: []
  topologySpreadConstraints: []
  upgradeStrategy: automatic
  volumeMounts: []
  volumes: []
opentelemetry-operator:
  admissionWebhooks:
    failurePolicy: Ignore
  crds:
    create: false
  enabled: false
  manager:
    collectorImage:
      repository: otel/opentelemetry-collector-k8s
prometheus-node-exporter:
  extraArgs:
  - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
  - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  namespaceOverride: ""
  podLabels:
    jobLabel: node-exporter
  prometheus:
    monitor:
      enabled: true
      interval: ""
      jobLabel: jobLabel
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      metricRelabelings: []
      proxyUrl: ""
      relabelings: []
      sampleLimit: 0
      scrapeTimeout: ""
      targetLimit: 0
  rbac:
    pspEnabled: false
  releaseLabel: true
  service:
    portName: http-metrics


